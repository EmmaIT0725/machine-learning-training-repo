# -*- coding: utf-8 -*-
"""복습과제_강민지28.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1P1vIQPx8wIqIzMGhE2JLHO2IBpvYPllc
"""

import pandas as pd
import seaborn as sns

dt = sns.load_dataset('titanic')

"""* groupby 문법
* 내가 원하는 컬럼 기준으로 그룹을 묶고 내가 원하는 값으로 통계치를 본다.
"""

dt

et_gr = dt.groupby('embark_town')

et_gr

for i, j in et_gr:
    print(i, '그룹 묶음')   # 키
    print(j)    # 값

for idx, j in enumerate(et_gr):
    print(f'{idx+1}번째 그룹')   # 키
    print(j)    # 값

# et_gr 그룹별로 확인
# get_group: 내가 원하는 그룹 가지고 올 수 있다.
et_gr.get_group('Cherbourg')
# 해당 명으로 접근해야 한다.

et_gr.get_group('Southampton')

"""* 두 개 이상 그룹 묶기"""

group2 = dt.groupby(['sex', 'embarked'])

for idx, j in enumerate(group2):
    print(f'{idx+1} 번째 그룹')       # 키(key)
    print(j)        # 값(value)

# 이름으로 직접 get_group 이용하기 >> () 괄호 이용하기
group2.get_group(('female', 'C'))

"""* 묶인 상태에서 평균 통계치 보는 경우"""

dt

dt.groupby('sex')['age'].mean()

# dt.groupby('sex'): sex별로 그룹묶기
# ['age'].mean(): age에 대한 통계를 보고 싶음.

# pclass 별로 생존자를 파악할 수 있음
dt.groupby('pclass')['survived'].sum()

dt.groupby('embark_town')['fare'].mean()

"""* groupby, agg함수
* agg (요약통계치를 여러 개 확인하거나, 내가 원하는 계산식 등을 적용할 때 사용 가능)
"""

dt.groupby('sex').agg('min', 'max')

# 우리가 만든 함수가 실제로 적용이 되는지 확인하기!
def min_max(x):
    return x.max()- x.min()

et_gr.agg(min_max)

"""## 데이터 병합
- 두 개의 데이터프레임을 붙인다.
- 두 개를 붙여서 우리가 확인해야 하는 상황
- 고객, 주문
- 하나의 테이블은 고객에 대한 정보
- 하나의 테이블은 주문에 대한 정보
- 고객이 어떤 주문을 했는지 보고싶어?
- 두 개의 테이블을 붙여서 고객과 주문에 대해서 같이 볼 수 있는 것
- 고객테이블 (고객아이디) 주문테이블 ( 주문번호, 제품명, 제품금액, 수량, 고객아이디 )
- 고객, 주문번호 ( 두 개가 고객테이블이 있다. )


---
- 판다스에서 제공하는 문법
- merge()
    - 기준 컬럼을 잡고 병합을 하는 경우
    - 공통의 컬럼을 하나 잡고 병합하고
    - left, right outer, inner 조인 방법이 다양하다.
    - 공통된 컬럼은 컬럼명이 아니라 컬럼 내에 값을 의미하는 것
    - 고객 아이디 라는 컬럼이 두 개 동일한데
    - 하나는 abcd1234 , 다른 하나는 -12312312숫자로 암호화 되어 있음 그럼 두 개는 공통된 컬럼이라 볼 수 없다.
- concat()
    - df1, df2 두 개의 테이터프레임이 있다면
    - 행 기준, 열 기준으로 붙인다.
    - df1 + df2 두 개로 덩어리 형태로 붙인다. ( 공통된 기준 컬럼이 없다. )
    - df1
    - '+'
    - df2
    
 ---
    
    - df1 + df2 + df3 + df4.. 붙여지는 경우
    
    - df1
    - '+'
    - df2
    - '+'
    - df3
    - ...
"""

t1 = pd.DataFrame({'학생번호' : [1, 2, 3, 4, 5],
                   '주문한 음식': ['피자', '치킨', '파스타', '김치찌개', '참치마요덮밥']})

t2 = pd.DataFrame({'학생번호' : [1, 2, 3, 4, 5],
                   '벌점 현황': [10, 2, 0, 6, 3]})

t1

t2

# pd.merge(왼쪽시작컬럼(기준),오른쪽 컬럼(기준 옆 붙일),how='병합방법',on='공통컬럼지정'(left_on, right_on))
display(t1)
display(t2)

pd.merge(t1, t2, how='inner')

pd.merge(t2, t1, how='inner')

t3 = pd.DataFrame({'주문한 음식': ['피자', '치킨', '파스타', '김치찌개', '참치마요덮밥'],
                   '학생번호' : [1, 2, 3, 4, 5]})

t4 = pd.DataFrame({'학생번호' : [1, 2, 3, 4, 5],
                   '상점 현황': [10, 2, 0, 6, 3]})

display(t3)
display(t4)

pd.merge(t3, t4, how='inner')

pd.merge(t4, t3, how='inner')

# pd.concat([df1, df2, df3....])
# default는 아래로 붙음(dim=0) >> 0 기준이 디폴트

# concat은 리스트 들어감
pd.concat([t1, t2])

# concat은 리스트 들어감
pd.concat([t1, t2], axis=1) # axis=1 : 열 기준
# axis 축을 지정하여 행, 열로 잡음
# 0은 행
# 1은 열

pd.concat([t3, t4]) # default : axis=0

pd.concat([t3, t4], axis=0)

pd.concat([t3, t4], axis=1)

"""- 범주형 데이터를 빠르게 카운팅하는 방법
- value_counts()
- value_counts(normalize=True,False) 총섬으로 나눠서 비율 계산
- value_counts(ascending=True,False) 값에 대한 내림차순이다.
"""

dt.value_counts('sex')

dt.value_counts('fare', normalize=True)

dt.value_counts('fare', normalize=False)

dt.value_counts('embark_town', normalize=True, ascending=True)

dt.value_counts('embark_town', normalize=False, ascending=True)

dt.value_counts('pclass', normalize=False, ascending=False)

"""# 타이타닉데이터를 가지고 시각화를 통해서 여러가지 컬럼들을 비교해 보자!
- EDA, 탐색적으로 데이터를 바라본다. 거기서 인사이트를 찾는다.
- 머신러닝 진행할 예정 -> 머신러닝은 결국 패턴 가지고 학습하는 것
- 생존과 생존하지 못한 데이터를 가지고 둘의 차이를 학습하고, 그 차이는 여러 컬럼에 따라 달라지는 것
- 그 컬럼들을 배우면서 -> 이러한 컬럼들의 패턴을 보이면 생존이다., 아니면 생존하지 못했다. 예측

---
- ML쪽은 y값(생존)에 따른 다른 피처들의 패턴이 정말 중요하다.
- 시각적으로 바라보거나, 기초통계적인 것으로도 봤을 때 y값과 다른 피처들의 관계가 정말 중요하다.
---
- ML 지도학습 -> 정답가지고 패턴 학습, 정답에 대한 패턴을 머신에게 얼마나 잘 알려주는지에 따라 성능도 올라간다.
- 기본적인 비즈니스 로직, 어떤 y값과 피처들의 로직이 명확하면 해당 피처를 사용해야 한다.
- 영업이익 계산하면-> 매출이런 것들 중요한 피처다.
- 머신에게 학습시킬 것들 중 정답에 대한 비중이 차이가 많이 나는 경우는 해당 피처를 사용할 수도 있다.
- A라는 피처와 B라는 피처가 있다.
- A는 정답 유뮤를 7:3으로 나눠준다. B는 5:5로 나눠준다. (Y값을 나눌 때)
- y값에 대해서 피처들이 어떤 식으로 나눠주는지, 패턴, 분포들이 보여지는지 이런 부분을 꼭 확인하고 작업을 해야 한다.

## Y값들과의 관계에 따른 다른 피처들 확인하자!
"""

dt[['sex', 'survived']]

dt[['sex', 'survived']].groupby('sex').sum().sort_values(by='survived', ascending=False)

dt[['pclass', 'survived']]

dt[['pclass', 'survived']].groupby('pclass').sum().sort_values(by='survived', ascending=False)

dt[['embark_town', 'fare']].groupby('embark_town').mean().sort_values(by='fare', ascending=False)

"""- 연속적인 값들도 같이 비교하기 위해서 시각화를 진행할 예정
- seaborn 패키지
- matplotlib 패키지
"""

# matplot 시각화 패키지를 가지고 오는 모듈
import matplotlib.pyplot as plt

# hist : plt.hist

g1 = sns.FacetGrid(dt, col='sex')
print(g1)
g1.map(plt.hist, 'age')

g2 = sns.FacetGrid(dt, col='embark_town')
g2.map(plt.hist, 'sex')

g2 = sns.FacetGrid(dt, col='embark_town')
g2.map(plt.hist, 'age')

g3 = sns.FacetGrid(dt, col = 'survived', row= 'sex')
g3.map(plt.hist, 'fare')

# pointplot을 통해서도 여러가지 볼 수 있다.
# sns.pointplot

g4 = sns.FacetGrid(dt, col='embark_town', row='sex')
g4.map(sns.pointplot, 'age')

g5 = sns.FacetGrid(dt, row='pclass')
g5.map(sns.pointplot, 'survived')

g5 = sns.FacetGrid(dt, col='pclass')
g5.map(sns.pointplot, 'fare', 'sex')

# barplot을 통해서도 여러가지 볼 수 있다.
# barplot: sns.barplot
g6=sns.FacetGrid(dt, col='sex',row = 'pclass')
g6.map(sns.barplot,'age','fare',alpha=0.2)
g6.add_legend() # 범례 설정

